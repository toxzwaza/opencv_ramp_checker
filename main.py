#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ©ãƒ³ãƒ—è‰²åˆ¤å®šçµ±åˆã‚·ã‚¹ãƒ†ãƒ 
ç”»åƒã‹ã‚‰ orange.png, green.png, red.png ã‚’åˆ‡ã‚Šå‡ºã—ã¦è‰²åˆ†æã‚’å®Ÿè¡Œ
"""

import cv2
import numpy as np
import os
import glob
import time
import csv
import random
from datetime import datetime, timedelta

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§ãƒ•ãƒ©ã‚°ç®¡ç†
current_state = None  # None: ç·‘ã¾ãŸã¯ãªã—, True: ã‚ªãƒ¬ãƒ³ã‚¸
orange_detection_start_time = None  # ã‚ªãƒ¬ãƒ³ã‚¸æ¤œçŸ¥é–‹å§‹æ™‚åˆ»
notification_sent = False  # é€šçŸ¥æ¸ˆã¿ãƒ•ãƒ©ã‚°
debug_mode = False  # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆåˆ†â†’ç§’å¤‰æ›ï¼‰

# ========================================
# 2.py ã‹ã‚‰ã®é–¢æ•°ï¼ˆç”»åƒåˆ‡ã‚Šå‡ºã—æ©Ÿèƒ½ï¼‰
# ========================================

def get_image_files():
    """sample_imgãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(glob.glob(os.path.join('sample_img', ext)))
        image_files.extend(glob.glob(os.path.join('sample_img', ext.upper())))
    
    # åˆ‡ã‚Šå‡ºã—æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–
    excluded_files = ['orange.png', 'green.png', 'cut.png']
    filtered_files = []
    
    for file in image_files:
        filename = os.path.basename(file)
        if filename not in excluded_files:
            filtered_files.append(file)
    
    return sorted(filtered_files)

def get_random_image_path():
    """1.pngã‹ã‚‰4.pngã¾ã§ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã§é¸æŠ"""
    available_images = []
    
    # 1.pngã‹ã‚‰4.pngã¾ã§ã®å­˜åœ¨ç¢ºèª
    for i in range(1, 5):
        image_path = os.path.join("sample_img", f"{i}.png")
        if os.path.exists(image_path):
            available_images.append(image_path)
    
    if not available_images:
        print("âŒ sample_imgãƒ•ã‚©ãƒ«ãƒ€ã«1.pngï½4.pngãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    selected_image = random.choice(available_images)
    image_name = os.path.basename(selected_image)
    
    print(f"[RANDOM] ãƒ©ãƒ³ãƒ€ãƒ é¸æŠç”»åƒ: {image_name} ({len(available_images)}/4å€‹åˆ©ç”¨å¯èƒ½)")
    return selected_image

def find_available_camera():
    """åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ã‚’æ¤œç´¢"""
    print("[CAMERA] åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ã‚’æ¤œç´¢ä¸­...")
    
    for camera_index in range(5):  # 0-4ç•ªã¾ã§æ¤œç´¢
        cap = cv2.VideoCapture(camera_index)
        if cap.isOpened():
            ret, frame = cap.read()
            cap.release()
            if ret:
                print(f"[FOUND] ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ {camera_index} ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                return camera_index
    
    print("[ERROR] åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return None

def capture_from_camera():
    """ã‚«ãƒ¡ãƒ©ã‹ã‚‰ç”»åƒã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦ä¿å­˜"""
    print("[CAMERA] ã‚«ãƒ¡ãƒ©ã‹ã‚‰ç”»åƒã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ä¸­...")
    
    # åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ã‚’æ¤œç´¢
    camera_index = find_available_camera()
    if camera_index is None:
        print("[ERROR] ã‚«ãƒ¡ãƒ©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")
        print("USBã‚«ãƒ¡ãƒ©ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        print("åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹:")
        print("  - /dev/video0 (é€šå¸¸ã®å†…è”µã‚«ãƒ¡ãƒ©)")
        print("  - /dev/video1 (USBå¤–éƒ¨ã‚«ãƒ¡ãƒ©)")
        return None
    
    # ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–
    cap = cv2.VideoCapture(camera_index)
    
    if not cap.isOpened():
        print(f"[ERROR] ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ {camera_index} ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    try:
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
        ret, frame = cap.read()
        
        if not ret:
            print("[ERROR] ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®ãƒ•ã‚¡ã‚¤ãƒ«åã§ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        capture_filename = f"camera_capture_{timestamp}.png"
        capture_path = os.path.join("sample_img", capture_filename)
        
        # ç”»åƒã‚’ä¿å­˜
        if cv2.imwrite(capture_path, frame):
            print(f"[OK] ã‚«ãƒ¡ãƒ©ç”»åƒã‚’ä¿å­˜: {capture_path}")
            print(f"ç”»åƒã‚µã‚¤ã‚º: {frame.shape[1]} x {frame.shape[0]}")
            return capture_path
        else:
            print("[ERROR] ã‚«ãƒ¡ãƒ©ç”»åƒã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
            
    finally:
        cap.release()
        print("ã‚«ãƒ¡ãƒ©ã‚’æ­£å¸¸ã«é–‰ã˜ã¾ã—ãŸ")

def draw_text_with_background(image, text, position, font_scale=0.35, color=(255, 255, 255), bg_color=(0, 0, 0), thickness=1):
    """èƒŒæ™¯ä»˜ãã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»"""
    font = cv2.FONT_HERSHEY_SIMPLEX
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’å–å¾—
    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
    
    # èƒŒæ™¯çŸ©å½¢ã‚’æç”»
    x, y = position
    cv2.rectangle(image, (x - 5, y - text_height - 5), 
                 (x + text_width + 5, y + baseline + 5), bg_color, -1)
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
    cv2.putText(image, text, position, font, font_scale, color, thickness)

def create_status_overlay(frame, detection_logs, current_time):
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã§è¡¨ç¤º"""
    global current_state, orange_detection_start_time, notification_sent, debug_mode
    
    overlay_frame = frame.copy()
    y_offset = 25
    line_height = 20
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    draw_text_with_background(overlay_frame, "LAMP DETECTION SYSTEM", (20, y_offset), 
                             font_scale=0.5, color=(255, 255, 255), bg_color=(0, 100, 200))
    y_offset += line_height + 5
    
    # ç¾åœ¨æ™‚åˆ»
    time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    draw_text_with_background(overlay_frame, f"TIME: {time_str}", (20, y_offset), 
                             color=(255, 255, 255), bg_color=(50, 50, 50))
    y_offset += line_height
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤º
    mode_text = "[DEBUG MODE]" if debug_mode else "[NORMAL MODE]"
    mode_color = (0, 255, 255) if debug_mode else (255, 255, 255)
    mode_bg = (100, 0, 100) if debug_mode else (50, 50, 50)
    draw_text_with_background(overlay_frame, mode_text, (20, y_offset), 
                             color=mode_color, bg_color=mode_bg)
    y_offset += line_height + 5
    
    # ç¾åœ¨ã®æ¤œçŸ¥çŠ¶æ…‹
    if current_state == True:
        status_text = "[ORANGE DETECTED]"
        status_color = (0, 165, 255)  # ã‚ªãƒ¬ãƒ³ã‚¸è‰²
        status_bg = (0, 50, 100)
        
        if orange_detection_start_time:
            elapsed = time.time() - orange_detection_start_time.timestamp()
            time_unit = "s" if debug_mode else "min"
            display_time = elapsed if debug_mode else elapsed / 60
            duration_text = f"Duration: {display_time:.1f}{time_unit}"
            
            # é€šçŸ¥ã¾ã§ã®æ®‹ã‚Šæ™‚é–“
            threshold_seconds = get_notification_threshold()
            remaining = max(0, threshold_seconds - elapsed)
            remaining_unit = "s" if debug_mode else "min"
            remaining_display = remaining if debug_mode else remaining / 60
            
            if remaining > 0:
                remaining_text = f"Alert in: {remaining_display:.1f}{remaining_unit}"
            else:
                remaining_text = "ALERT SENT" if notification_sent else "ALERT READY"
    else:
        status_text = "[GREEN/NONE DETECTED]"
        status_color = (0, 255, 0)  # ç·‘è‰²
        status_bg = (0, 100, 0)
        duration_text = "Duration: --"
        remaining_text = "Alert: --"
    
    draw_text_with_background(overlay_frame, status_text, (20, y_offset), 
                             font_scale=0.5, color=status_color, bg_color=status_bg)
    y_offset += line_height
    
    draw_text_with_background(overlay_frame, duration_text, (20, y_offset), 
                             color=(255, 255, 255), bg_color=(50, 50, 50))
    y_offset += line_height
    
    draw_text_with_background(overlay_frame, remaining_text, (20, y_offset), 
                             color=(255, 255, 255), bg_color=(50, 50, 50))
    y_offset += line_height + 5
    
    # æ¤œçŸ¥ãƒ­ã‚°ã®è¡¨ç¤ºï¼ˆæœ€æ–°5ä»¶ï¼‰
    if detection_logs:
        draw_text_with_background(overlay_frame, "RECENT DETECTIONS:", (20, y_offset), 
                                 font_scale=0.4, color=(255, 255, 255), bg_color=(100, 100, 0))
        y_offset += line_height
        
        recent_logs = detection_logs[-5:]  # æœ€æ–°5ä»¶
        for log in recent_logs:
            log_color = (0, 165, 255) if "ORANGE" in log else (0, 255, 0)
            draw_text_with_background(overlay_frame, log, (30, y_offset), 
                                     font_scale=0.3, color=log_color, bg_color=(30, 30, 30))
            y_offset += 15
    
    # æ“ä½œèª¬æ˜
    y_offset += 5
    draw_text_with_background(overlay_frame, "Press ESC or 'q' to quit", (20, y_offset), 
                             font_scale=0.3, color=(255, 255, 255), bg_color=(100, 0, 0))
    
    return overlay_frame

def run_camera_with_live_display():
    """ã‚«ãƒ¡ãƒ©æ˜ åƒã‚’å¸¸æ™‚è¡¨ç¤ºã—ãªãŒã‚‰å®šæœŸçš„ã«è‰²æ¤œå‡ºã‚’å®Ÿè¡Œ"""
    global current_state, orange_detection_start_time, notification_sent, debug_mode
    
    print("[CAMERA] ãƒ©ã‚¤ãƒ–ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
    print("=" * 60)
    
    # åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ã‚’æ¤œç´¢
    camera_index = find_available_camera()
    if camera_index is None:
        print("[ERROR] ã‚«ãƒ¡ãƒ©ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return False
    
    # ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–
    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        print(f"[ERROR] ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ {camera_index} ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return False
    
    # åˆæœŸçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    current_state = None
    orange_detection_start_time = None
    notification_sent = False
    
    # CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–
    initialize_csv_log()
    
    # æ¤œçŸ¥é–“éš”ã®è¨­å®š
    detection_interval = 1 if debug_mode else 60  # ãƒ‡ãƒãƒƒã‚°: 1ç§’, é€šå¸¸: 60ç§’
    last_detection_time = 0
    
    time_unit = get_time_unit()
    threshold_value = 10
    
    print(f"ã‚«ãƒ¡ãƒ©æ˜ åƒ: å…¨ç”»é¢ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º")
    print(f"è‰²æ¤œå‡ºé–“éš”: {detection_interval}ç§’")
    print(f"[ORANGE] ã‚ªãƒ¬ãƒ³ã‚¸{threshold_value}{time_unit}é–“é€£ç¶šæ¤œçŸ¥ã§é€šçŸ¥é€ä¿¡")
    if debug_mode:
        print("[WARNING] ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æ™‚é–“å˜ä½ãŒç§’ã«å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™")
    print("ESCã‚­ãƒ¼ã¾ãŸã¯'q'ã‚­ãƒ¼ã§çµ‚äº†")
    print("=" * 60)
    
    # æ¤œçŸ¥ãƒ­ã‚°ã‚’ä¿æŒ
    detection_logs = []
    
    # å…¨ç”»é¢è¡¨ç¤ºç”¨ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½œæˆ
    window_name = 'Live Camera Feed - LAMP DETECTION'
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
    
    try:
        while True:
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
            ret, frame = cap.read()
            if not ret:
                detection_logs.append(f"{datetime.now().strftime('%H:%M:%S')} - ERROR: Frame capture failed")
                break
            
            # ç¾åœ¨æ™‚åˆ»
            current_time_unix = time.time()
            current_datetime = datetime.now()
            
            # å®šæœŸçš„ã«è‰²æ¤œå‡ºã‚’å®Ÿè¡Œ
            if current_time_unix - last_detection_time >= detection_interval:
                last_detection_time = current_time_unix
                
                # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜
                timestamp = current_datetime.strftime("%Y%m%d_%H%M%S")
                temp_filename = f"temp_frame_{timestamp}.png"
                temp_path = os.path.join("sample_img", temp_filename)
                
                if cv2.imwrite(temp_path, frame):
                    detection_logs.append(f"{current_datetime.strftime('%H:%M:%S')} - DETECTION: Processing...")
                    
                    # è‰²æ¤œå‡ºå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã‚’æŠ‘åˆ¶ï¼‰
                    # process_single_analysis ã®ä»£ã‚ã‚Šã«ç›´æ¥å‡¦ç†
                    if crop_and_save_all_colors(temp_path):
                        results = run_analysis_silent()  # é™éŸ³ç‰ˆã®åˆ†æ
                        if results and len(results) == 2:
                            judgment, confidence, reasons, scores = comprehensive_judgment(results)
                            
                            # æ¤œçŸ¥çµæœã‹ã‚‰å‰²åˆã‚’å–å¾—
                            orange_percentage = 0
                            green_percentage = 0
                            for result in results:
                                if result['expected_color'] == 'ã‚ªãƒ¬ãƒ³ã‚¸':
                                    orange_percentage = result['percentage']
                                elif result['expected_color'] == 'ç·‘':
                                    green_percentage = result['percentage']
                            
                            # ãƒ•ãƒ©ã‚°çŠ¶æ…‹ã‚’æ›´æ–°
                            detection_state = update_detection_state(judgment, orange_percentage, green_percentage, os.path.basename(temp_path))
                            
                            # ãƒ­ã‚°ã«è¨˜éŒ²
                            log_entry = f"{current_datetime.strftime('%H:%M:%S')} - {judgment} (O:{orange_percentage:.1f}% G:{green_percentage:.1f}%)"
                            detection_logs.append(log_entry)
                            
                            # ãƒ­ã‚°ãŒå¤šã™ãã‚‹å ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
                            if len(detection_logs) > 10:
                                detection_logs = detection_logs[-10:]
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    try:
                        os.remove(temp_path)
                    except:
                        pass
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã—ã¦è¡¨ç¤º
            display_frame = create_status_overlay(frame, detection_logs, current_time_unix)
            
            # æ¬¡å›æ¤œçŸ¥ã¾ã§ã®æ™‚é–“ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            next_detection_in = detection_interval - (current_time_unix - last_detection_time)
            if next_detection_in > 0:
                next_text = f"Next detection: {next_detection_in:.0f}s"
                draw_text_with_background(display_frame, next_text, (20, frame.shape[0] - 30), 
                                        font_scale=0.4, color=(255, 255, 0), bg_color=(50, 50, 0))
            
            cv2.imshow(window_name, display_frame)
            
            # ã‚­ãƒ¼å…¥åŠ›ã‚’ãƒã‚§ãƒƒã‚¯
            key = cv2.waitKey(1) & 0xFF
            if key == 27 or key == ord('q'):  # ESCã‚­ãƒ¼ã¾ãŸã¯'q'ã‚­ãƒ¼ã§çµ‚äº†
                print("\n[EXIT] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹çµ‚äº†è¦æ±‚")
                break
                
    except KeyboardInterrupt:
        print("\n[EXIT] ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã§çµ‚äº†")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("[CAMERA] ã‚«ãƒ¡ãƒ©ã¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æ­£å¸¸ã«é–‰ã˜ã¾ã—ãŸ")
        return True

def get_color_coordinates():
    """å„è‰²ã®åº§æ¨™ç¯„å›²ã‚’å®šç¾©"""
    color_coordinates = {
        'orange': (297, 86, 347, 133),  # (x1, y1, x2, y2)
        'green': (303, 110, 350, 164),  # greenã®åº§æ¨™ç¯„å›²
    }
    return color_coordinates

def crop_and_save_all_colors(image_path):
    """ã™ã¹ã¦ã®è‰²åº§æ¨™ã§ç”»åƒã‚’åˆ‡ã‚Šå‡ºã—ã¦ä¿å­˜"""
    print(f"\nç”»åƒåˆ‡ã‚Šå‡ºã—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    print("=" * 50)
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    original_image = cv2.imread(image_path)
    if original_image is None:
        print("ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    
    print(f"å…ƒç”»åƒ: {os.path.basename(image_path)}")
    print(f"å…ƒç”»åƒã‚µã‚¤ã‚º: {original_image.shape[1]} x {original_image.shape[0]}")
    
    color_coordinates = get_color_coordinates()
    success_count = 0
    
    for color_name, coordinates in color_coordinates.items():
        x1, y1, x2, y2 = coordinates
        
        # åº§æ¨™ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        height, width = original_image.shape[:2]
        x1 = max(0, min(x1, width))
        y1 = max(0, min(y1, height))
        x2 = max(0, min(x2, width))
        y2 = max(0, min(y2, height))
        
        if x1 >= x2 or y1 >= y2:
            print(f"âš ï¸ {color_name}ã®åº§æ¨™ç¯„å›²ãŒç„¡åŠ¹ã§ã™")
            continue
        
        # ç”»åƒã‚’åˆ‡ã‚Šå‡ºã—
        cropped_image = original_image[y1:y2, x1:x2]
        
        # ä¿å­˜
        extension = os.path.splitext(image_path)[1] or '.png'
        output_filename = f"{color_name}{extension}"
        output_path = os.path.join("sample_img", output_filename)
        
        if cv2.imwrite(output_path, cropped_image):
            print(f"âœ“ {color_name}: ({x1}, {y1}) â†’ ({x2}, {y2}) | ã‚µã‚¤ã‚º: {cropped_image.shape[1]}x{cropped_image.shape[0]}")
            success_count += 1
        else:
            print(f"âŒ {color_name}ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    print(f"\nåˆ‡ã‚Šå‡ºã—å®Œäº†: {success_count}/2 ãƒ•ã‚¡ã‚¤ãƒ«")
    return success_count == 2

# ========================================
# 3.py ã‹ã‚‰ã®é–¢æ•°ï¼ˆè‰²åˆ†ææ©Ÿèƒ½ï¼‰
# ========================================

def load_image(image_path):
    """ç”»åƒã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(image_path):
        return None
    
    image = cv2.imread(image_path)
    if image is None:
        return None
    
    return image

def get_default_color_ranges():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è‰²ç¯„å›²è¨­å®šã‚’å–å¾—"""
    return {
        'ã‚ªãƒ¬ãƒ³ã‚¸': [
            (np.array([11, 50, 50]), np.array([25, 255, 255]))      # ã‚ªãƒ¬ãƒ³ã‚¸è‰²
        ],
        'ç·‘': [
            (np.array([40, 50, 50]), np.array([80, 255, 255]))      # ç·‘è‰²
        ]
    }

def get_enhanced_color_ranges():
    """æ¤œå‡ºç²¾åº¦ã‚’å‘ä¸Šã•ã›ãŸè‰²ç¯„å›²è¨­å®š"""
    return {
        'ã‚ªãƒ¬ãƒ³ã‚¸': [
            # ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã®ç¯„å›²ã‚’æ‹¡å¼µ
            (np.array([8, 30, 30]), np.array([30, 255, 255]))       # ã‚ªãƒ¬ãƒ³ã‚¸è‰²ï¼ˆæ‹¡å¼µï¼‰
        ],
        'ç·‘': [
            # ç·‘è‰²ã®ç¯„å›²ã‚’æ‹¡å¼µ
            (np.array([35, 30, 30]), np.array([85, 255, 255]))      # ç·‘è‰²ï¼ˆæ‹¡å¼µï¼‰
        ]
    }

def create_custom_color_ranges(orange_ranges=None, green_ranges=None):
    """ã‚«ã‚¹ã‚¿ãƒ è‰²ç¯„å›²ã‚’ä½œæˆ"""
    custom_ranges = {}
    
    if orange_ranges:
        custom_ranges['ã‚ªãƒ¬ãƒ³ã‚¸'] = orange_ranges
    if green_ranges:
        custom_ranges['ç·‘'] = green_ranges
    
    # æŒ‡å®šã•ã‚Œãªã‹ã£ãŸè‰²ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
    default_ranges = get_default_color_ranges()
    for color, ranges in default_ranges.items():
        if color not in custom_ranges:
            custom_ranges[color] = ranges
    
    return custom_ranges

def analyze_lamp_color(image, color_ranges=None, apply_preprocessing=True):
    """ãƒ©ãƒ³ãƒ—ã®è‰²ã‚’åˆ†æã™ã‚‹ï¼ˆè‰²ç¯„å›²ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯¾å¿œï¼‰"""
    if image is None:
        return None
    
    # å‰å‡¦ç†ã‚’é©ç”¨ï¼ˆãƒã‚¤ã‚ºé™¤å»ã¨è‰²ã®å¼·èª¿ï¼‰
    if apply_preprocessing:
        image = preprocess_image_for_color_detection(image)
    
    # BGR ã‹ã‚‰ HSV è‰²ç©ºé–“ã«å¤‰æ›
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    
    # è‰²ç¯„å›²ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯æ‹¡å¼µç‰ˆã‚’ä½¿ç”¨
    if color_ranges is None:
        color_ranges = get_enhanced_color_ranges()
    
    color_pixels = {}
    
    for color_name, ranges in color_ranges.items():
        total_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)
        
        for lower, upper in ranges:
            mask = cv2.inRange(hsv, lower, upper)
            total_mask = cv2.bitwise_or(total_mask, mask)
        
        pixel_count = cv2.countNonZero(total_mask)
        color_pixels[color_name] = pixel_count
    
    return color_pixels

def preprocess_image_for_color_detection(image):
    """è‰²æ¤œå‡ºã®ãŸã‚ã®å‰å‡¦ç†"""
    # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã§ãƒã‚¤ã‚ºã‚’é™¤å»
    blurred = cv2.GaussianBlur(image, (3, 3), 0)
    
    # å½©åº¦ã‚’å°‘ã—å¼·èª¿
    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
    hsv[:, :, 1] = cv2.multiply(hsv[:, :, 1], 1.2)  # å½©åº¦ã‚’20%å‘ä¸Š
    
    # HSVã‹ã‚‰BGRã«æˆ»ã™
    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    
    return enhanced

def calibrate_color_detection(image_path):
    """è‰²æ¤œå‡ºã®æ ¡æ­£ã‚’è¡Œã†å¯¾è©±çš„ãªé–¢æ•°"""
    print("ğŸ¨ è‰²æ¤œå‡ºæ ¡æ­£ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {image_path}")
        return None
    
    print(f"ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {os.path.basename(image_path)}")
    print("ç”»åƒã‚µã‚¤ã‚º:", image.shape[1], "x", image.shape[0])
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€æ‹¡å¼µã€ã‚«ã‚¹ã‚¿ãƒ ã®3ã¤ã®ãƒ¢ãƒ¼ãƒ‰ã§æ¯”è¼ƒ
    modes = {
        "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ": get_default_color_ranges(),
        "æ‹¡å¼µç‰ˆ": get_enhanced_color_ranges()
    }
    
    print("\nğŸ“Š å„ãƒ¢ãƒ¼ãƒ‰ã§ã®æ¤œå‡ºçµæœ:")
    print("-" * 50)
    
    best_mode = None
    best_total = 0
    
    for mode_name, color_ranges in modes.items():
        print(f"\nğŸ” {mode_name}ãƒ¢ãƒ¼ãƒ‰:")
        color_pixels = analyze_lamp_color(image, color_ranges)
        
        total_pixels = sum(color_pixels.values())
        
        for color, count in color_pixels.items():
            percentage = (count / total_pixels * 100) if total_pixels > 0 else 0
            print(f"  {color}: {count} ãƒ”ã‚¯ã‚»ãƒ« ({percentage:.1f}%)")
        
        print(f"  åˆè¨ˆæ¤œå‡ºãƒ”ã‚¯ã‚»ãƒ«: {total_pixels}")
        
        if total_pixels > best_total:
            best_total = total_pixels
            best_mode = mode_name
    
    print(f"\nğŸ† æ¨å¥¨ãƒ¢ãƒ¼ãƒ‰: {best_mode} (æ¤œå‡ºãƒ”ã‚¯ã‚»ãƒ«æ•°: {best_total})")
    
    # ã‚«ã‚¹ã‚¿ãƒ èª¿æ•´ã®ææ¡ˆ
    print(f"\nâš™ï¸ ã‚«ã‚¹ã‚¿ãƒ èª¿æ•´ã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
    print("1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨")
    print("2. æ‹¡å¼µè¨­å®šã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰")
    print("3. æ‰‹å‹•ã§è‰²ç¯„å›²ã‚’èª¿æ•´")
    print("4. è¦–è¦šçš„ã«è‰²ç¯„å›²ã‚’ç¢ºèª")
    
    while True:
        try:
            choice = input("é¸æŠã—ã¦ãã ã•ã„ (1-4): ").strip()
            
            if choice == "1":
                return get_default_color_ranges()
            elif choice == "2":
                return get_enhanced_color_ranges()
            elif choice == "3":
                return manual_color_adjustment()
            elif choice == "4":
                visual_color_range_check(image, modes["æ‹¡å¼µç‰ˆ"])
                continue
            else:
                print("ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚1-4ã®æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        except KeyboardInterrupt:
            print("\næ ¡æ­£ã‚’çµ‚äº†ã—ã¾ã™")
            return get_enhanced_color_ranges()

def manual_color_adjustment():
    """æ‰‹å‹•ã§è‰²ç¯„å›²ã‚’èª¿æ•´"""
    print("\nğŸ”§ æ‰‹å‹•è‰²ç¯„å›²èª¿æ•´")
    print("HSVå€¤ã®ç¯„å›²ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    print("å½¢å¼: H_min,S_min,V_min,H_max,S_max,V_max")
    print("ä¾‹: 0,30,30,15,255,255")
    
    custom_ranges = {}
    
    colors = ['ã‚ªãƒ¬ãƒ³ã‚¸', 'ç·‘']
    for color in colors:
        print(f"\n{color}ã®ç¯„å›²ã‚’è¨­å®š:")
        
        try:
            if color == 'ã‚ªãƒ¬ãƒ³ã‚¸':
                range_input = input(f"ç¯„å›² (ä¾‹: 8,30,30,30,255,255): ").strip()
            else:  # ç·‘
                range_input = input(f"ç¯„å›² (ä¾‹: 35,30,30,85,255,255): ").strip()
            
            values = [int(x) for x in range_input.split(',')]
            
            custom_ranges[color] = [
                (np.array(values[:3]), np.array(values[3:]))
            ]
        except:
            print("ç„¡åŠ¹ãªå½¢å¼ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            custom_ranges[color] = get_default_color_ranges()[color]
    
    return custom_ranges

def visual_color_range_check(image, color_ranges):
    """è¦–è¦šçš„ã«è‰²ç¯„å›²ã‚’ç¢ºèª"""
    print("\nğŸ‘ï¸ è¦–è¦šçš„è‰²ç¯„å›²ç¢ºèª")
    print("å„è‰²ã®ãƒã‚¹ã‚¯ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ESCã‚­ãƒ¼ã§æ¬¡ã®è‰²ã«é€²ã¿ã¾ã™ã€‚")
    
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    
    for color_name, ranges in color_ranges.items():
        print(f"\n{color_name}ã®æ¤œå‡ºç¯„å›²ã‚’è¡¨ç¤ºä¸­...")
        
        total_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)
        
        for lower, upper in ranges:
            mask = cv2.inRange(hsv, lower, upper)
            total_mask = cv2.bitwise_or(total_mask, mask)
        
        # å…ƒç”»åƒã¨ãƒã‚¹ã‚¯ã‚’è¡¨ç¤º
        result = cv2.bitwise_and(image, image, mask=total_mask)
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´
        cv2.namedWindow(f'{color_name} - å…ƒç”»åƒ', cv2.WINDOW_NORMAL)
        cv2.namedWindow(f'{color_name} - ãƒã‚¹ã‚¯', cv2.WINDOW_NORMAL)
        cv2.namedWindow(f'{color_name} - æ¤œå‡ºçµæœ', cv2.WINDOW_NORMAL)
        
        cv2.imshow(f'{color_name} - å…ƒç”»åƒ', image)
        cv2.imshow(f'{color_name} - ãƒã‚¹ã‚¯', total_mask)
        cv2.imshow(f'{color_name} - æ¤œå‡ºçµæœ', result)
        
        pixel_count = cv2.countNonZero(total_mask)
        print(f"{color_name}ã®æ¤œå‡ºãƒ”ã‚¯ã‚»ãƒ«æ•°: {pixel_count}")
        
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    print("è¦–è¦šçš„ç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

def analyze_brightness(image):
    """ç”»åƒã®æ˜åº¦ã‚’åˆ†æ"""
    if image is None:
        return False, 0
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    mean_brightness = np.mean(gray)
    is_bright = mean_brightness > 100  # é–¾å€¤
    
    return is_bright, mean_brightness

def analyze_single_image(image_path, expected_color):
    """å˜ä¸€ç”»åƒã§æœŸå¾…ã•ã‚Œã‚‹è‰²ã®å«æœ‰ç‡ã‚’åˆ†æ"""
    image = load_image(image_path)
    if image is None:
        return None
    
    # è‰²åˆ†æ
    color_pixels = analyze_lamp_color(image)
    if not color_pixels:
        return None
    
    # æœŸå¾…ã•ã‚Œã‚‹è‰²ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã‚’å–å¾—
    expected_pixels = color_pixels.get(expected_color, 0)
    total_pixels = sum(color_pixels.values())
    
    if total_pixels > 0:
        percentage = (expected_pixels / total_pixels) * 100
    else:
        percentage = 0
    
    # æ˜åº¦åˆ†æ
    is_bright, brightness = analyze_brightness(image)
    
    result = {
        'file_name': os.path.basename(image_path),
        'expected_color': expected_color,
        'expected_pixels': expected_pixels,
        'total_color_pixels': total_pixels,
        'percentage': percentage,
        'is_bright': is_bright,
        'brightness': brightness,
        'all_colors': color_pixels
    }
    
    return result

def comprehensive_judgment(results):
    """ç·åˆçš„ãªåˆ¤å®šã‚’è¡Œã†"""
    if not results or len(results) != 2:
        return "åˆ¤å®šä¸å¯", 0, ["åˆ†æçµæœãŒä¸å®Œå…¨ã§ã™"]
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœã‚’è©•ä¾¡
    scores = {}
    threshold = 30.0  # æœŸå¾…è‰²ã®æœ€å°å‰²åˆé–¾å€¤
    brightness_threshold = 80.0  # æ˜åº¦é–¾å€¤
    
    for result in results:
        color = result['expected_color']
        percentage = result['percentage']
        brightness = result['brightness']
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæœŸå¾…è‰²å‰²åˆ + æ˜åº¦ãƒœãƒ¼ãƒŠã‚¹ï¼‰
        score = percentage
        if brightness > brightness_threshold:
            score += 10  # æ˜åº¦ãƒœãƒ¼ãƒŠã‚¹
        
        scores[color] = {
            'score': score,
            'percentage': percentage,
            'brightness': brightness,
            'meets_threshold': percentage >= threshold
        }
    
    # æœ€é«˜ã‚¹ã‚³ã‚¢ã®è‰²ã‚’åˆ¤å®š
    best_color = max(scores.items(), key=lambda x: x[1]['score'])
    color_name, color_data = best_color
    
    # åˆ¤å®šç†ç”±ã‚’ç”Ÿæˆ
    reasons = []
    
    if color_data['meets_threshold']:
        reasons.append(f"{color_name}ã®å«æœ‰ç‡ãŒ{color_data['percentage']:.1f}%ã§é–¾å€¤({threshold}%)ã‚’è¶…é")
    
    if color_data['brightness'] > brightness_threshold:
        reasons.append(f"ååˆ†ãªæ˜åº¦({color_data['brightness']:.1f})ã‚’æ¤œå‡º")
    
    # ä»–ã®è‰²ã¨ã®æ¯”è¼ƒ
    other_colors = [c for c in scores.keys() if c != color_name]
    for other_color in other_colors:
        if scores[other_color]['percentage'] < threshold:
            reasons.append(f"{other_color}ã¯å«æœ‰ç‡{scores[other_color]['percentage']:.1f}%ã§é–¾å€¤æœªæº€")
    
    # æœ€çµ‚åˆ¤å®š
    if color_data['meets_threshold']:
        judgment = color_name
        confidence = min(95, color_data['score'])  # æœ€å¤§95%
    else:
        judgment = "ä¸æ˜"
        confidence = 0
        reasons = ["ã™ã¹ã¦ã®è‰²ãŒé–¾å€¤ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ"]
    
    return judgment, confidence, reasons, scores

def get_time_unit():
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦æ™‚é–“å˜ä½ã‚’å–å¾—"""
    global debug_mode
    return "ç§’" if debug_mode else "åˆ†"

def get_notification_threshold():
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦é€šçŸ¥é–¾å€¤ã‚’å–å¾—ï¼ˆç§’å˜ä½ï¼‰"""
    global debug_mode
    return 10 if debug_mode else (10 * 60)  # ãƒ‡ãƒãƒƒã‚°: 10ç§’, é€šå¸¸: 10åˆ†

def get_time_delta(minutes=10):
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦timedeltaã‚’å–å¾—"""
    global debug_mode
    if debug_mode:
        return timedelta(seconds=minutes)  # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã¯åˆ†ã‚’ç§’ã¨ã—ã¦æ‰±ã†
    else:
        return timedelta(minutes=minutes)

def format_time_remaining(remaining_seconds):
    """æ®‹ã‚Šæ™‚é–“ã‚’é©åˆ‡ãªå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    global debug_mode
    
    if debug_mode:
        return f"{int(remaining_seconds)}ç§’"
    else:
        remaining_minutes = remaining_seconds // 60
        remaining_sec = int(remaining_seconds % 60)
        return f"{int(remaining_minutes):02d}:{remaining_sec:02d}"

def send_notification(message):
    """é€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹é–¢æ•°ï¼ˆç¾åœ¨ã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼‰"""
    global debug_mode
    
    print("\n" + "!" * 60)
    print("!!! é‡è¦ãªé€šçŸ¥ !!!")
    if debug_mode:
        print("!!! [DEBUG MODE] !!!")
    print("!" * 60)
    print(f"MESSAGE: {message}")
    print(f"TIME: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    if debug_mode:
        print("WARNING: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ - 10ç§’é–“é€£ç¶šæ¤œçŸ¥")
    print("!" * 60)
    print()

def update_detection_state(judgment, orange_percentage=0, green_percentage=0, image_file=""):
    """æ¤œçŸ¥çŠ¶æ…‹ã‚’æ›´æ–°ã—ã€å¿…è¦ã«å¿œã˜ã¦é€šçŸ¥ã‚’é€ä¿¡"""
    global current_state, orange_detection_start_time, notification_sent, debug_mode
    
    current_time = datetime.now()
    time_unit = get_time_unit()
    threshold_seconds = get_notification_threshold()
    
    if judgment == "ã‚ªãƒ¬ãƒ³ã‚¸":
        if current_state != True:
            # ã‚ªãƒ¬ãƒ³ã‚¸æ¤œçŸ¥é–‹å§‹
            current_state = True
            orange_detection_start_time = current_time
            notification_sent = False
            debug_info = " [ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰]" if debug_mode else ""
            print(f"[ORANGE] ã‚ªãƒ¬ãƒ³ã‚¸æ¤œçŸ¥é–‹å§‹: {current_time.strftime('%H:%M:%S')}{debug_info}")
            
            # CSVè¨˜éŒ²: ã‚ªãƒ¬ãƒ³ã‚¸æ¤œçŸ¥é–‹å§‹
            log_to_csv("orange_start", judgment, orange_percentage, green_percentage, 0, image_file)
        else:
            # ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ¤œçŸ¥ä¸­
            if orange_detection_start_time and not notification_sent:
                elapsed_time = current_time - orange_detection_start_time
                elapsed_seconds = elapsed_time.total_seconds()
                
                if elapsed_seconds >= threshold_seconds:
                    # é–¾å€¤æ™‚é–“é€£ç¶šã§ã‚ªãƒ¬ãƒ³ã‚¸ã‚’æ¤œçŸ¥
                    message = f"ã‚ªãƒ¬ãƒ³ã‚¸ãƒ©ãƒ³ãƒ—ãŒ10{time_unit}é–“é€£ç¶šã§ç‚¹ç¯ã—ã¦ã„ã¾ã™ï¼"
                    send_notification(message)
                    notification_sent = True
                    
                    # CSVè¨˜éŒ²: é€šçŸ¥é€ä¿¡
                    log_to_csv("notification", judgment, orange_percentage, green_percentage, elapsed_seconds, image_file)
                else:
                    # æ®‹ã‚Šæ™‚é–“ã‚’è¡¨ç¤º
                    remaining_seconds = threshold_seconds - elapsed_seconds
                    remaining_formatted = format_time_remaining(remaining_seconds)
                    print(f"[ORANGE] ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šä¸­ - é€šçŸ¥ã¾ã§æ®‹ã‚Š: {remaining_formatted}")
                    
                    # CSVè¨˜éŒ²: ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶š
                    log_to_csv("orange_continue", judgment, orange_percentage, green_percentage, elapsed_seconds, image_file)
    
    elif judgment == "ç·‘":
        duration = 0
        if current_state == True and orange_detection_start_time:
            # ã‚ªãƒ¬ãƒ³ã‚¸ã‹ã‚‰ç·‘ã«å¤‰åŒ– - ç¶™ç¶šæ™‚é–“ã‚’è¨ˆç®—
            elapsed_time = current_time - orange_detection_start_time
            duration = elapsed_time.total_seconds()
            
            # ç¶™ç¶šæ™‚é–“ã‚’å¼·èª¿è¡¨ç¤º
            formatted_duration = format_duration_for_display(duration)
            print(f"[GREEN] ç·‘ã«å¤‰åŒ– - ã‚ªãƒ¬ãƒ³ã‚¸çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ: {current_time.strftime('%H:%M:%S')}")
            print(f"[DURATION] ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“: {formatted_duration}")
            
            # CSVè¨˜éŒ²: ã‚ªãƒ¬ãƒ³ã‚¸çµ‚äº†
            log_to_csv("orange_end", judgment, orange_percentage, green_percentage, duration, image_file)
            
            # å³åº§ã«ç¶™ç¶šæ™‚é–“åˆ†æã‚’è¡¨ç¤º
            print(f"\n" + "="*25 + " æ”¹å–„ãƒ‡ãƒ¼ã‚¿ " + "="*25)
            analyze_orange_durations()
            print("="*60)
        else:
            # CSVè¨˜éŒ²: ç·‘æ¤œçŸ¥
            log_to_csv("green_detection", judgment, orange_percentage, green_percentage, 0, image_file)
            
        current_state = None
        orange_detection_start_time = None
        notification_sent = False
        
    else:  # judgment == "ä¸æ˜" or ãã®ä»–
        duration = 0
        if current_state == True and orange_detection_start_time:
            # ã‚ªãƒ¬ãƒ³ã‚¸ã‹ã‚‰ä¸æ˜ã«å¤‰åŒ– - ç¶™ç¶šæ™‚é–“ã‚’è¨ˆç®—
            elapsed_time = current_time - orange_detection_start_time
            duration = elapsed_time.total_seconds()
            print(f"[UNKNOWN] æ¤œçŸ¥ä¸æ˜ - ã‚ªãƒ¬ãƒ³ã‚¸çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ: {current_time.strftime('%H:%M:%S')}")
            
            # CSVè¨˜éŒ²: ã‚ªãƒ¬ãƒ³ã‚¸ä¸­æ–­
            log_to_csv("orange_interrupted", judgment, orange_percentage, green_percentage, duration, image_file)
        else:
            # CSVè¨˜éŒ²: ä¸æ˜æ¤œçŸ¥
            log_to_csv("unknown_detection", judgment, orange_percentage, green_percentage, 0, image_file)
            
        current_state = None
        orange_detection_start_time = None
        notification_sent = False
    
    return current_state

def get_detection_status():
    """ç¾åœ¨ã®æ¤œçŸ¥çŠ¶æ…‹ã‚’å–å¾—"""
    global current_state, orange_detection_start_time, notification_sent
    
    status = {
        'current_state': current_state,
        'orange_start_time': orange_detection_start_time,
        'notification_sent': notification_sent
    }
    
    if current_state == True and orange_detection_start_time:
        elapsed_time = datetime.now() - orange_detection_start_time
        elapsed_seconds = elapsed_time.total_seconds()
        threshold_seconds = get_notification_threshold()
        
        if debug_mode:
            status['elapsed_seconds'] = elapsed_seconds
            status['remaining_seconds'] = max(0, threshold_seconds - elapsed_seconds)
        else:
            status['elapsed_minutes'] = elapsed_seconds / 60
            status['remaining_minutes'] = max(0, (threshold_seconds - elapsed_seconds) / 60)
    
    return status

def initialize_csv_log():
    """CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–"""
    csv_file = "data.csv"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
    if not os.path.exists(csv_file):
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                "timestamp", 
                "event_type", 
                "detection_result", 
                "orange_percentage", 
                "green_percentage", 
                "duration_seconds", 
                "debug_mode",
                "image_file"
            ])
        print(f"[CSV] CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {csv_file}")

def log_to_csv(event_type, detection_result, orange_percentage=0, green_percentage=0, duration_seconds=0, image_file=""):
    """æ¤œçŸ¥ã‚¤ãƒ™ãƒ³ãƒˆã‚’CSVã«è¨˜éŒ²"""
    global debug_mode
    
    csv_file = "data.csv"
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    try:
        with open(csv_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                timestamp,
                event_type,
                detection_result,
                f"{orange_percentage:.1f}",
                f"{green_percentage:.1f}",
                f"{duration_seconds:.1f}",
                "debug" if debug_mode else "normal",
                image_file
            ])
        
        # ã‚ªãƒ¬ãƒ³ã‚¸ã‹ã‚‰ç·‘ã¸ã®åˆ‡ã‚Šæ›¿ã‚ã‚Šæ™‚é–“ã¯ç‰¹åˆ¥ã«å¼·èª¿è¡¨ç¤º
        if event_type == "orange_end" and duration_seconds > 0:
            time_unit = "ç§’" if debug_mode else "åˆ†"
            display_duration = duration_seconds if debug_mode else duration_seconds / 60
            print(f"[IMPORTANT] ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“: {display_duration:.1f}{time_unit}")
            print(f"[CSV] è¨˜éŒ²: {event_type} - {detection_result} (ç¶™ç¶šæ™‚é–“: {duration_seconds:.1f}ç§’, ç”»åƒ: {image_file})")
        else:
            print(f"[CSV] è¨˜éŒ²: {event_type} - {detection_result}")
    except Exception as e:
        print(f"âŒ CSVè¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

def analyze_orange_durations():
    """ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“ã®åˆ†æã‚’å®Ÿè¡Œ"""
    csv_file = "data.csv"
    
    if not os.path.exists(csv_file):
        print("âŒ data.csvãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    try:
        durations = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row['event_type'] == 'orange_end' and float(row['duration_seconds']) > 0:
                    durations.append({
                        'timestamp': row['timestamp'],
                        'duration': float(row['duration_seconds']),
                        'mode': row['debug_mode']
                    })
        
        if not durations:
            print("ğŸ“Š ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“")
            return
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
        duration_values = [d['duration'] for d in durations]
        avg_duration = sum(duration_values) / len(duration_values)
        min_duration = min(duration_values)
        max_duration = max(duration_values)
        
        print(f"\nğŸ“Š ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 50)
        print(f"ç·è¨˜éŒ²æ•°: {len(durations)}å›")
        print(f"å¹³å‡ç¶™ç¶šæ™‚é–“: {avg_duration:.1f}ç§’")
        print(f"æœ€çŸ­ç¶™ç¶šæ™‚é–“: {min_duration:.1f}ç§’")
        print(f"æœ€é•·ç¶™ç¶šæ™‚é–“: {max_duration:.1f}ç§’")
        
        # æœ€è¿‘ã®å‚¾å‘ã‚’è¡¨ç¤ºï¼ˆæœ€æ–°5å›ï¼‰
        if len(durations) >= 2:
            recent_durations = durations[-5:]
            print(f"\nğŸ“ˆ æœ€è¿‘ã®ç¶™ç¶šæ™‚é–“æ¨ç§»:")
            print("-" * 30)
            for i, d in enumerate(recent_durations, 1):
                mode_indicator = "ğŸ›" if d['mode'] == 'debug' else "â°"
                print(f"{i}. {d['timestamp']}: {d['duration']:.1f}ç§’ {mode_indicator}")
            
            # æ”¹å–„å‚¾å‘ã®åˆ†æ
            if len(recent_durations) >= 2:
                first_duration = recent_durations[0]['duration']
                last_duration = recent_durations[-1]['duration']
                improvement = first_duration - last_duration
                
                print(f"\nğŸ“‰ æ”¹å–„çŠ¶æ³:")
                if improvement > 0:
                    print(f"âœ… æ”¹å–„ä¸­: {improvement:.1f}ç§’çŸ­ç¸®")
                elif improvement < 0:
                    print(f"âš ï¸ æ‚ªåŒ–: {abs(improvement):.1f}ç§’å»¶é•·")
                else:
                    print(f"â¡ï¸ æ¨ªã°ã„")
        
    except Exception as e:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def format_duration_for_display(seconds):
    """ç¶™ç¶šæ™‚é–“ã‚’è¦‹ã‚„ã™ã„å½¢å¼ã§è¡¨ç¤º"""
    global debug_mode
    
    if debug_mode:
        return f"{seconds:.1f}ç§’"
    else:
        if seconds < 60:
            return f"{seconds:.1f}ç§’"
        else:
            minutes = seconds / 60
            return f"{minutes:.1f}åˆ† ({seconds:.1f}ç§’)"

def run_analysis():
    """åˆ†æã‚’å®Ÿè¡Œ"""
    print(f"\nè‰²åˆ†æå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    print("=" * 50)
    
    # åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã¨æœŸå¾…è‰²ã®å®šç¾©
    target_files = [
        ("green.png", "ç·‘"),
        ("orange.png", "ã‚ªãƒ¬ãƒ³ã‚¸")
    ]
    
    results = []
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
    for filename, expected_color in target_files:
        image_path = os.path.join("sample_img", filename)
        result = analyze_single_image(image_path, expected_color)
        if result:
            results.append(result)
            print(f"âœ“ {filename}: {expected_color} {result['percentage']:.1f}% (æ˜åº¦: {result['brightness']:.1f})")
        else:
            print(f"âŒ {filename}ã®åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    return results

def run_analysis_silent():
    """åˆ†æã‚’å®Ÿè¡Œï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã‚’æŠ‘åˆ¶ï¼‰"""
    # åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã¨æœŸå¾…è‰²ã®å®šç¾©
    target_files = [
        ("green.png", "ç·‘"),
        ("orange.png", "ã‚ªãƒ¬ãƒ³ã‚¸")
    ]
    
    results = []
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
    for filename, expected_color in target_files:
        image_path = os.path.join("sample_img", filename)
        result = analyze_single_image_silent(image_path, expected_color)
        if result:
            results.append(result)
    
    return results

def analyze_single_image_silent(image_path, expected_color):
    """å˜ä¸€ç”»åƒã§æœŸå¾…ã•ã‚Œã‚‹è‰²ã®å«æœ‰ç‡ã‚’åˆ†æï¼ˆé™éŸ³ç‰ˆï¼‰"""
    image = load_image(image_path)
    if image is None:
        return None
    
    # è‰²åˆ†æ
    color_pixels = analyze_lamp_color(image)
    if not color_pixels:
        return None
    
    # æœŸå¾…ã•ã‚Œã‚‹è‰²ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã‚’å–å¾—
    expected_pixels = color_pixels.get(expected_color, 0)
    total_pixels = sum(color_pixels.values())
    
    if total_pixels > 0:
        percentage = (expected_pixels / total_pixels) * 100
    else:
        percentage = 0
    
    # æ˜åº¦åˆ†æ
    is_bright, brightness = analyze_brightness_silent(image)
    
    result = {
        'file_name': os.path.basename(image_path),
        'expected_color': expected_color,
        'expected_pixels': expected_pixels,
        'total_color_pixels': total_pixels,
        'percentage': percentage,
        'is_bright': is_bright,
        'brightness': brightness,
        'all_colors': color_pixels
    }
    
    return result

def analyze_brightness_silent(image):
    """ç”»åƒã®æ˜åº¦ã‚’åˆ†æï¼ˆé™éŸ³ç‰ˆï¼‰"""
    if image is None:
        return False, 0
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    mean_brightness = np.mean(gray)
    is_bright = mean_brightness > 100  # é–¾å€¤
    
    return is_bright, mean_brightness

# ========================================
# ãƒ¡ã‚¤ãƒ³çµ±åˆå‡¦ç†
# ========================================

def process_single_analysis(image_path, mode="å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«"):
    """å˜ä¸€ã®åˆ†æå‡¦ç†ã‚’å®Ÿè¡Œ"""
    print(f"\n{'=' * 60}")
    print(f"ğŸš¦ ãƒ©ãƒ³ãƒ—è‰²åˆ¤å®šçµ±åˆã‚·ã‚¹ãƒ†ãƒ  ({mode})")
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    print("1. ç”»åƒã‹ã‚‰ orange.png, green.png ã‚’åˆ‡ã‚Šå‡ºã—")
    print("2. å„ãƒ•ã‚¡ã‚¤ãƒ«ã®è‰²åˆ†æã‚’å®Ÿè¡Œ")
    print("3. ç·åˆåˆ¤å®šçµæœã‚’è¡¨ç¤º")
    print("=" * 60)
    
    # Step 1: ç”»åƒç¢ºèª
    print(f"\nğŸ“ Step 1: ç”»åƒç¢ºèª ({mode})")
    if image_path is None:
        print("âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        return False
    
    # ä½¿ç”¨ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
    image_filename = os.path.basename(image_path) if image_path else ""
    
    # Step 2: åˆ‡ã‚Šå‡ºã—å‡¦ç†
    print(f"\nâœ‚ï¸ Step 2: ç”»åƒåˆ‡ã‚Šå‡ºã—")
    if not crop_and_save_all_colors(image_path):
        print("âŒ ç”»åƒã®åˆ‡ã‚Šå‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    
    # Step 3: è‰²åˆ†æ
    print(f"\nğŸ” Step 3: è‰²åˆ†æ")
    results = run_analysis()
    
    if not results:
        print("âŒ è‰²åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    
    # Step 4: ç·åˆåˆ¤å®š
    print(f"\nğŸ¯ Step 4: ç·åˆåˆ¤å®š")
    print("=" * 50)
    
    judgment, confidence, reasons, scores = comprehensive_judgment(results)
    
    # è©³ç´°çµæœè¡¨ç¤º
    print("ğŸ“Š å„ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æçµæœ:")
    print("-" * 30)
    for result in results:
        color = result['expected_color']
        score_data = scores[color]
        status = "ğŸŸ¢" if score_data['meets_threshold'] else "ğŸ”´"
        
        print(f"{status} {result['file_name']}:")
        print(f"   æœŸå¾…è‰²({color}): {result['percentage']:.1f}%")
        print(f"   æ˜åº¦: {result['brightness']:.1f}")
        print(f"   ã‚¹ã‚³ã‚¢: {score_data['score']:.1f}")
        print(f"   é–¾å€¤ã‚¯ãƒªã‚¢: {'âœ“' if score_data['meets_threshold'] else 'âœ—'}")
        print()
    
    # æœ€çµ‚åˆ¤å®šçµæœ
    print("ğŸ† æœ€çµ‚åˆ¤å®šçµæœ:")
    print("-" * 30)
    print(f"åˆ¤å®šè‰²: {judgment}")
    if judgment != "ä¸æ˜":
        print(f"ä¿¡é ¼åº¦: {confidence:.1f}%")
    
    print(f"\nğŸ“ åˆ¤å®šç†ç”±:")
    for i, reason in enumerate(reasons, 1):
        print(f"  {i}. {reason}")
    
    # ã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“‹ åˆ†æã‚µãƒãƒªãƒ¼:")
    print("-" * 30)
    for result in results:
        status = "ğŸŸ¢" if result['percentage'] >= 30 else "ğŸ”´"
        print(f"{status} {result['file_name']}: {result['expected_color']} {result['percentage']:.1f}%")
    
    # æ¤œçŸ¥çµæœã‹ã‚‰å‰²åˆã‚’å–å¾—
    orange_percentage = 0
    green_percentage = 0
    
    for result in results:
        if result['expected_color'] == 'ã‚ªãƒ¬ãƒ³ã‚¸':
            orange_percentage = result['percentage']
        elif result['expected_color'] == 'ç·‘':
            green_percentage = result['percentage']
    
    # ãƒ•ãƒ©ã‚°çŠ¶æ…‹ã‚’æ›´æ–°ï¼ˆç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã‚‚æ¸¡ã™ï¼‰
    detection_state = update_detection_state(judgment, orange_percentage, green_percentage, image_filename)
    
    # æ¤œçŸ¥çŠ¶æ…‹ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
    status_info = get_detection_status()
    print(f"\nğŸ·ï¸ æ¤œçŸ¥çŠ¶æ…‹æƒ…å ±:")
    print("-" * 30)
    print(f"ç¾åœ¨ã®çŠ¶æ…‹: {'ğŸŸ  ã‚ªãƒ¬ãƒ³ã‚¸' if detection_state == True else 'ğŸŸ¢ ç·‘/ãªã—'}")
    
    if detection_state == True:
        if debug_mode and status_info.get('elapsed_seconds') is not None:
            elapsed_sec = status_info['elapsed_seconds']
            remaining_sec = status_info.get('remaining_seconds', 0)
            print(f"ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“: {elapsed_sec:.1f}ç§’")
            if remaining_sec > 0:
                print(f"é€šçŸ¥ã¾ã§æ®‹ã‚Š: {remaining_sec:.1f}ç§’")
            else:
                print(f"é€šçŸ¥çŠ¶æ…‹: {'é€ä¿¡æ¸ˆã¿' if status_info['notification_sent'] else 'æœªé€ä¿¡'}")
        elif not debug_mode and status_info.get('elapsed_minutes') is not None:
            elapsed_min = status_info['elapsed_minutes']
            remaining_min = status_info.get('remaining_minutes', 0)
            print(f"ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“: {elapsed_min:.1f}åˆ†")
            if remaining_min > 0:
                print(f"é€šçŸ¥ã¾ã§æ®‹ã‚Š: {remaining_min:.1f}åˆ†")
            else:
                print(f"é€šçŸ¥çŠ¶æ…‹: {'é€ä¿¡æ¸ˆã¿' if status_info['notification_sent'] else 'æœªé€ä¿¡'}")
    
    print(f"\nâœ… å‡¦ç†å®Œäº†!")
    return True

def run_fixed_file_mode():
    """ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ"""
    image_path = get_random_image_path()
    return process_single_analysis(image_path, "ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒ")

def run_camera_mode():
    """ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ"""
    image_path = capture_from_camera()
    return process_single_analysis(image_path, "ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒ—ãƒãƒ£")

def run_loop_mode(mode="fixed", interval_minutes=10):
    """ãƒ«ãƒ¼ãƒ—ãƒ¢ãƒ¼ãƒ‰ã§å®šæœŸå®Ÿè¡Œ"""
    global current_state, orange_detection_start_time, notification_sent, debug_mode
    
    time_unit = get_time_unit()
    threshold_value = 10
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã¯å®Ÿè¡Œé–“éš”ã‚‚èª¿æ•´
    if debug_mode:
        actual_interval = interval_minutes * 60  # åˆ†ã‚’ç§’ã«å¤‰æ›
        interval_display = f"{actual_interval:.0f}ç§’"
    else:
        actual_interval = interval_minutes
        interval_display = f"{interval_minutes}åˆ†"
    
    print(f"ğŸ”„ ãƒ«ãƒ¼ãƒ—ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
    print(f"å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {'ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒ' if mode == 'fixed' else 'ã‚«ãƒ¡ãƒ©'}")
    print(f"å®Ÿè¡Œé–“éš”: {interval_display}")
    print(f"ğŸŸ  ã‚ªãƒ¬ãƒ³ã‚¸{threshold_value}{time_unit}é–“é€£ç¶šæ¤œçŸ¥ã§é€šçŸ¥é€ä¿¡")
    if debug_mode:
        print("âš ï¸ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æ™‚é–“å˜ä½ãŒç§’ã«å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™")
    if mode == 'fixed':
        print("ğŸ² æ¯å›1.pngï½4.pngã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ")
    print("Ctrl+C ã§åœæ­¢ã§ãã¾ã™")
    print("=" * 60)
    
    # åˆæœŸçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    current_state = None
    orange_detection_start_time = None
    notification_sent = False
    
    # CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–
    initialize_csv_log()
    
    execution_count = 0
    
    try:
        while True:
            execution_count += 1
            print(f"\nğŸ”„ å®Ÿè¡Œå›æ•°: {execution_count}")
            
            # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å‡¦ç†
            if mode == "fixed":
                success = run_fixed_file_mode()
            else:  # camera
                success = run_camera_mode()
            
            if success:
                print(f"âœ… å®Ÿè¡Œ #{execution_count} å®Œäº†")
            else:
                print(f"âŒ å®Ÿè¡Œ #{execution_count} å¤±æ•—")
            
            # æ¬¡å›å®Ÿè¡Œæ™‚åˆ»ã‚’è¨ˆç®—ãƒ»è¡¨ç¤º
            if debug_mode:
                next_time = datetime.now() + timedelta(seconds=actual_interval)
                print(f"\nâ° æ¬¡å›å®Ÿè¡Œäºˆå®š: {next_time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"ğŸ’¤ {actual_interval:.0f}ç§’é–“å¾…æ©Ÿä¸­...")
                # æŒ‡å®šæ™‚é–“å¾…æ©Ÿ
                time.sleep(actual_interval)
            else:
                next_time = datetime.now() + timedelta(minutes=actual_interval)
                print(f"\nâ° æ¬¡å›å®Ÿè¡Œäºˆå®š: {next_time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"ğŸ’¤ {actual_interval}åˆ†é–“å¾…æ©Ÿä¸­...")
                # æŒ‡å®šæ™‚é–“å¾…æ©Ÿ
                time.sleep(actual_interval * 60)
            
    except KeyboardInterrupt:
        print(f"\n\nğŸ›‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹åœæ­¢è¦æ±‚ã‚’å—ä¿¡")
        print(f"ç·å®Ÿè¡Œå›æ•°: {execution_count}")
        print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™")

def toggle_debug_mode():
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ"""
    global debug_mode
    
    print("\nâš™ï¸ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®š")
    print("=" * 40)
    print(f"ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰: {'ãƒ‡ãƒãƒƒã‚° (10ç§’)' if debug_mode else 'é€šå¸¸ (10åˆ†)'}")
    print("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã¯10åˆ†â†’10ç§’ã«å¤‰æ›´ã•ã‚Œã¾ã™")
    
    choice = input("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower().strip()
    debug_mode = choice in ['y', 'yes']
    
    print(f"è¨­å®šå®Œäº†: {'ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰' if debug_mode else 'é€šå¸¸ãƒ¢ãƒ¼ãƒ‰'}")
    return debug_mode

def display_menu():
    """ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤º"""
    global debug_mode
    
    print("\n[LAMP] ãƒ©ãƒ³ãƒ—è‰²åˆ¤å®šçµ±åˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    print("å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒ (1.png-4.png) - 1å›å®Ÿè¡Œ")
    print("2. ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒ—ãƒãƒ£ - 1å›å®Ÿè¡Œ")
    interval_text = "1ç§’æ¯" if debug_mode else "1åˆ†æ¯"
    print(f"3. ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒ - {interval_text}ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ")
    print(f"4. ãƒ©ã‚¤ãƒ–ã‚«ãƒ¡ãƒ© - æ˜ åƒè¡¨ç¤º+{interval_text}è‰²æ¤œå‡º")
    print("5. è‰²æ¤œå‡ºæ ¡æ­£ãƒ„ãƒ¼ãƒ« (green/orange)")
    print("6. ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®š")
    print("7. ã‚ªãƒ¬ãƒ³ã‚¸ç¶™ç¶šæ™‚é–“åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    debug_indicator = "[DEBUG] ãƒ‡ãƒãƒƒã‚° (10ç§’)" if debug_mode else "[NORMAL] é€šå¸¸ (10åˆ†)"
    print(f"ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰: {debug_indicator}")

def select_mode():
    """å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ"""
    global debug_mode
    
    display_menu()
    
    while True:
        try:
            choice = input("é¸æŠã—ã¦ãã ã•ã„ (1-7): ").strip()
            
            if choice == "1":
                return "fixed_single"
            elif choice == "2":
                return "camera_single"
            elif choice == "3":
                return "fixed_loop"
            elif choice == "4":
                return "camera_loop"
            elif choice == "5":
                return "calibrate"
            elif choice == "6":
                toggle_debug_mode()
                display_menu()  # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å†è¡¨ç¤º
                continue
            elif choice == "7":
                analyze_orange_durations()
                input("\nä½•ã‹ã‚­ãƒ¼ã‚’æŠ¼ã™ã¨ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«æˆ»ã‚Šã¾ã™...")
                display_menu()  # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å†è¡¨ç¤º
                continue
            else:
                print("ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚1-7ã®æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        except KeyboardInterrupt:
            print("\nçµ‚äº†ã—ã¾ã™")
            return None

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    mode = select_mode()
    if mode is None:
        return
    
    print(f"\né¸æŠã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰: {mode}")
    print("=" * 60)
    
    if mode == "fixed_single":
        run_fixed_file_mode()
    elif mode == "camera_single":
        run_camera_mode()
    elif mode == "fixed_loop":
        interval = 1/60 if debug_mode else 1  # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: 1ç§’, é€šå¸¸: 1åˆ†
        run_loop_mode("fixed", interval)
    elif mode == "camera_loop":
        run_camera_with_live_display()
    elif mode == "calibrate":
        # æ ¡æ­£ãƒ¢ãƒ¼ãƒ‰
        image_path = get_random_image_path()
        if image_path:
            calibrate_color_detection(image_path)
        else:
            print("âŒ æ ¡æ­£ç”¨ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

if __name__ == "__main__":
    main()
